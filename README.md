# ML-Foundations-From-Dirty-Data-to-Prediction
End-to-end machine learning foundations project showcasing real-world data cleaning, preprocessing, feature engineering, and feature selection using Titanic and retail sales datasetsâ€”focusing on transforming messy data into ML-ready pipelines and meaningful insights.

.

ğŸš€ End-to-End Machine Learning Foundations

From Raw, Messy Data to ML-Ready Pipelines

ğŸ“Œ Overview

Real-world data is rarely clean, structured, or ready for machine learning.
This repository brings together multiple real-world datasets and projects to demonstrate a complete machine learning foundation workflow â€” starting from raw, inconsistent data and ending with clean, transformed, and feature-optimized datasets suitable for modeling.

Instead of treating each dataset as a separate beginner project, this repository consolidates them into one unified ML learning journey, reflecting how data science is actually practiced in industry.

ğŸ§  What This Repository Demonstrates

This project focuses on the most critical (and often underestimated) part of machine learning â€” data preparation and feature engineering.

Core Skills Covered

Exploratory Data Analysis (EDA)

Handling missing and inconsistent data

Data cleaning and preprocessing pipelines

Feature transformation (log, scaling, encoding)

Automated and manual feature selection

Preparing datasets for downstream ML models

Extracting meaningful, business-oriented insights

ğŸ“‚ Project Structure
End-to-End-ML-Foundations/
â”‚
â”œâ”€â”€ 1_Data_Understanding/
â”‚   â”œâ”€â”€ Titanic_EDA.ipynb
â”‚   â”œâ”€â”€ Retail_Sales_EDA.ipynb
â”‚
â”œâ”€â”€ 2_Data_Cleaning/
â”‚   â”œâ”€â”€ Missing_Value_Imputation.ipynb
â”‚   â”œâ”€â”€ Outlier_Detection_Handling.ipynb
â”‚
â”œâ”€â”€ 3_Feature_Engineering/
â”‚   â”œâ”€â”€ Log_Transformations.ipynb
â”‚   â”œâ”€â”€ Encoding_and_Scaling.ipynb
â”‚
â”œâ”€â”€ 4_Feature_Selection/
â”‚   â”œâ”€â”€ Sequential_Feature_Selection.ipynb
â”‚   â”œâ”€â”€ Correlation_Based_Filtering.ipynb
â”‚
â”œâ”€â”€ 5_Model_Ready_Data/
â”‚   â”œâ”€â”€ Final_Cleaned_Datasets.ipynb
â”‚
â”œâ”€â”€ 6_Insights/
â”‚   â””â”€â”€ Business_and_Data_Insights.md
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸ“Š Datasets Used
1ï¸âƒ£ Titanic Dataset

Used to practice:

Missing value imputation

Categorical encoding

Feature relevance analysis

Preparing structured data for classification tasks

2ï¸âƒ£ Retail Store Sales Dataset

Used to practice:

Handling real-world noisy data

Log-based feature transformations

Feature selection using Sequential Feature Selector (SFS)

Converting raw transactional data into ML-ready format

ğŸ” Key Techniques & Approaches
ğŸ§¹ Data Cleaning

Mean / Median / Mode imputation

Domain-based missing value handling

Outlier detection and treatment

âš™ï¸ Feature Engineering

Log and power transformations

Scaling and normalization

Encoding categorical variables

ğŸ¯ Feature Selection

Sequential Feature Selection (SFS)

Correlation filtering

Dimensionality reduction mindset

ğŸ“ˆ Why This Project Matters

Many beginner ML projects jump straight to models.
This repository focuses on what actually determines model performance in the real world â€” data quality and feature design.

By combining multiple datasets and techniques into a single pipeline, this project reflects:

Real industry workflows

Reusability of preprocessing logic

Structured ML thinking over isolated experiments

ğŸ”— Related Projects

This repository consolidates and builds upon earlier individual projects:

Titanic Data Preprocessing

Retail Store Sales Data Cleaning

Feature Transformation & Selection

ZenNy â€“ The AI Wallet (Applied ML Product)

ZenNy represents the application of these foundational ML concepts in a product-oriented setting.

ğŸš€ Future Enhancements

Convert preprocessing steps into reusable Python modules

Integrate sklearn.Pipeline

Add baseline ML models for benchmarking

Expand to additional real-world datasets
